{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.15\n",
      "0.3.5\n"
     ]
    }
   ],
   "source": [
    "import langchain_core, langchain_community\n",
    "print(langchain_core.__version__)\n",
    "print(langchain_community.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from ollama import Message\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "client = ollama.Client(host='http://localhost:11434')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llama3.1',\n",
       " 'created_at': '2024-11-02T04:41:39.1422069Z',\n",
       " 'message': {'role': 'assistant',\n",
       "  'content': \"It's nice to meet you. Is there something I can help you with or would you like to chat?\"},\n",
       " 'done_reason': 'stop',\n",
       " 'done': True,\n",
       " 'total_duration': 872554900,\n",
       " 'load_duration': 19668900,\n",
       " 'prompt_eval_count': 13,\n",
       " 'prompt_eval_duration': 274509000,\n",
       " 'eval_count': 23,\n",
       " 'eval_duration': 577555000}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chat\n",
    "client.chat(\"llama3.1\", messages=[Message(role=\"user\", content=\"Hey there!\")], stream=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's nice to meet you. Is there something I can help you with or would you like to chat?"
     ]
    }
   ],
   "source": [
    "# streaming\n",
    "for token in client.chat(\"llama3.1\", messages=[Message(role=\"user\", content=\"Hey there!\")],stream=True):\n",
    "    print(token['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'location': {'name': 'New York', 'region': 'New York', 'country': 'United States of America', 'lat': 40.714, 'lon': -74.006, 'tz_id': 'America/New_York', 'localtime_epoch': 1730522499, 'localtime': '2024-11-02 00:41'}, 'current': {'last_updated_epoch': 1730521800, 'last_updated': '2024-11-02 00:30', 'temp_c': 13.9, 'temp_f': 57.0, 'is_day': 0, 'condition': {'text': 'Clear', 'icon': '//cdn.weatherapi.com/weather/64x64/night/113.png', 'code': 1000}, 'wind_mph': 12.8, 'wind_kph': 20.5, 'wind_degree': 320, 'wind_dir': 'NW', 'pressure_mb': 1021.0, 'pressure_in': 30.14, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 51, 'cloud': 0, 'feelslike_c': 12.3, 'feelslike_f': 54.1, 'windchill_c': 11.6, 'windchill_f': 52.9, 'heatindex_c': 13.2, 'heatindex_f': 55.7, 'dewpoint_c': 4.2, 'dewpoint_f': 39.5, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.0, 'gust_mph': 16.2, 'gust_kph': 26.1}}\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tool calling\n",
    "tool = TavilySearchResults(max_results=1)\n",
    "\n",
    "def tavily_search(query:str)->str:\n",
    "    return tool.invoke({\"query\":query})[0]['content']\n",
    "\n",
    "tavily_search(\"What is the weather in New York City?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.1', 'created_at': '2024-11-02T04:44:09.0753535Z', 'message': {'role': 'assistant', 'content': 'The current weather in New York City is:\\n\\n* Temperature: 57째F (13.9째C)\\n* Conditions: Clear\\n* Wind: 20.5 km/h (12.8 mph) from the NW at a pressure of 30.14 inches and humidity of 51%\\n* Precipitation: None\\n* Visibility: 16 kilometers (9 miles)\\n\\nNote: This is an automated response generated based on the provided data, please check other sources for more accurate and up-to-date information.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3695887500, 'load_duration': 13125900, 'prompt_eval_count': 414, 'prompt_eval_duration': 593064000, 'eval_count': 104, 'eval_duration': 3088555000}\n"
     ]
    }
   ],
   "source": [
    "available_tools = {\"tavily_search\": tavily_search}\n",
    "\n",
    "response = client.chat(\n",
    "    \"llama3.1\", \n",
    "    messages=[\n",
    "        Message(role=\"user\", content=\"What is the weather in New York City?\")\n",
    "    ],\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": 'function',\n",
    "            'function': {\n",
    "                \"name\": 'tavily_search',\n",
    "                \"description\": \"Search up-to-date information on internet.\",\n",
    "                \"parameters\":{\n",
    "                    'type': 'object',\n",
    "                    'properties': {\n",
    "                        'query': {\n",
    "                            'type': 'string',\n",
    "                            'description': 'a query to find on internet',\n",
    "                        },\n",
    "                    },\n",
    "                    'required':['query'],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "for called_tool in response['message']['tool_calls']:\n",
    "    function_to_call = available_tools[called_tool['function']['name']]\n",
    "    function_response = function_to_call(**called_tool['function']['arguments'])\n",
    "    messages = [\n",
    "        Message(role=\"user\", content=\"What is the weather in New York City?\"),\n",
    "        Message(role=\"tool\", content=function_response)\n",
    "    ]\n",
    "\n",
    "final_response = client.chat(model=\"llama3.1\", messages=messages)\n",
    "print(final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in New York City is:\n",
      "\n",
      "* Temperature: 57째F (13.9째C)\n",
      "* Conditions: Clear\n",
      "* Wind: 20.5 km/h (12.8 mph) from the NW at a pressure of 30.14 inches and humidity of 51%\n",
      "* Precipitation: None\n",
      "* Visibility: 16 kilometers (9 miles)\n",
      "\n",
      "Note: This is an automated response generated based on the provided data, please check other sources for more accurate and up-to-date information.\n"
     ]
    }
   ],
   "source": [
    "print(final_response['message']['content'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
