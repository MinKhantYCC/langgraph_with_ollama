{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model:ChatOpenAI, tools, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_do18dqhw', 'function': {'arguments': '{\"query\":\"SF weather\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 260, 'total_tokens': 282, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-5c32a8b9-7f91-4fe4-875d-a485615462f6-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'SF weather'}, 'id': 'call_do18dqhw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 260, 'output_tokens': 22, 'total_tokens': 282, 'input_token_details': {}, 'output_token_details': {}})]\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'SF weather'}, 'id': 'call_do18dqhw', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "[ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1730819573, \\'localtime\\': \\'2024-11-05 07:12\\'}, \\'current\\': {\\'last_updated_epoch\\': 1730818800, \\'last_updated\\': \\'2024-11-05 07:00\\', \\'temp_c\\': 11.1, \\'temp_f\\': 52.0, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 2.2, \\'wind_kph\\': 3.6, \\'wind_degree\\': 30, \\'wind_dir\\': \\'NNE\\', \\'pressure_mb\\': 1020.0, \\'pressure_in\\': 30.12, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 97, \\'cloud\\': 50, \\'feelslike_c\\': 11.5, \\'feelslike_f\\': 52.6, \\'windchill_c\\': 12.7, \\'windchill_f\\': 54.9, \\'heatindex_c\\': 12.7, \\'heatindex_f\\': 54.8, \\'dewpoint_c\\': 10.3, \\'dewpoint_f\\': 50.6, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 0.0, \\'gust_mph\\': 3.1, \\'gust_kph\\': 5.0}}\"}, {\\'url\\': \\'https://world-weather.info/forecast/usa/san_francisco/may-2024/\\', \\'content\\': \\'Detailed ‚ö° San Francisco Weather Forecast for May 2024 - day/night üå°Ô∏è temperatures, precipitations - World-Weather.info. Add the current city. Search. Weather; Archive; Widgets ¬∞F. World; United States; California; Weather in San Francisco; ... 11 +66¬∞ +55¬∞ 12 +63¬∞ +54¬∞ 13\\'}]', name='tavily_search_results_json', tool_call_id='call_do18dqhw')]\n",
      "[AIMessage(content='The weather in SF is currently partly cloudy with a temperature of 52¬∞F (11.1¬∞C). There is no precipitation expected.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 678, 'total_tokens': 706, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-a4fc1349-50f4-4d7e-9a2f-5e7bc55f87c1-0', usage_metadata={'input_tokens': 678, 'output_tokens': 28, 'total_tokens': 706, 'input_token_details': {}, 'output_token_details': {}})]\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "model = ChatOpenAI(\n",
    "    api_key=\"ollama\",\n",
    "    model=\"llama3.1\",\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    ")\n",
    "\n",
    "with SqliteSaver.from_conn_string(\":memory:\") as memory:\n",
    "    abot = Agent(model, [tool], system=prompt, checkpointer=memory)\n",
    "    messages = [HumanMessage(content=\"What is the weather in SF?\")]\n",
    "    thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "    for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "        for v in event.values():\n",
    "            print(v['messages'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
